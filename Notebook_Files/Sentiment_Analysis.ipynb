{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9dad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tweepy\n",
    "\n",
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7e286fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sarva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#initial imports\n",
    "import tweepy \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tweepy import OAuthHandler \n",
    "from tweepy import Cursor \n",
    "import nltk as nltk\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1de912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings Twitter API Key\n",
    "api_key='2LEkmltQnjgt4NEwAiU3wKfiU'\n",
    "api_key_secret='Jg0Fl7wkEAVSbJnXpHXXZEySZka9Dg3FxW8H3tqCfaoFjrsowc'\n",
    "\n",
    "acc_token='143141229-1gfi2d61Aco7beRwqgxTo8DdzjWmaKLmqPZgVepA'\n",
    "acc_secret='4Cxbo1eNgS6DF69gF7vJ01IXE2hhU7Uo3qAjgvskhTTfo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "213f0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_twitter_auth():\n",
    "    \"\"\"\n",
    "    @return:\n",
    "        - the authentification to Twitter\n",
    "    \"\"\"\n",
    "    try:\n",
    "        consumer_key = api_key\n",
    "        consumer_secret = api_key_secret\n",
    "        access_token = acc_token\n",
    "        access_secret = acc_secret\n",
    "        \n",
    "    except KeyError:\n",
    "        sys.stderr.write(\"Twitter Environment Variable not Set\\n\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    \n",
    "    return auth\n",
    "\n",
    "def get_twitter_client():\n",
    "    \"\"\"\n",
    "    @return:\n",
    "        - the client to access the authentification API\n",
    "    \"\"\"\n",
    "    auth = get_twitter_auth()\n",
    "    client = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    return client\n",
    "\n",
    "def get_tweets_from_user(twitter_user_name, page_limit=16, count_tweet=20):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        - twitter_user_name: the twitter username of a user (company, etc.)\n",
    "        - page_limit: the total number of pages (max=16)\n",
    "        - count_tweet: maximum number to be retrieved from a page\n",
    "        \n",
    "    @return\n",
    "        - all the tweets from the user twitter_user_name\n",
    "    \"\"\"\n",
    "    client = get_twitter_client()\n",
    "    \n",
    "    all_tweets = []\n",
    "    \n",
    "    for page in Cursor(client.user_timeline, \n",
    "                        screen_name=twitter_user_name, \n",
    "                        count=count_tweet).pages(page_limit):\n",
    "        for tweet in page:\n",
    "            parsed_tweet = {}\n",
    "            parsed_tweet['date'] = tweet.created_at\n",
    "            parsed_tweet['author'] = tweet.user.name\n",
    "            parsed_tweet['twitter_name'] = tweet.user.screen_name\n",
    "            parsed_tweet['text'] = tweet.text\n",
    "            parsed_tweet['number_of_likes'] = tweet.favorite_count\n",
    "            parsed_tweet['number_of_retweets'] = tweet.retweet_count\n",
    "                \n",
    "            all_tweets.append(parsed_tweet)\n",
    "    \n",
    "    # Create dataframe \n",
    "    df = pd.DataFrame(all_tweets)\n",
    "    \n",
    "    # Revome duplicates if there are any\n",
    "    df = df.drop_duplicates( \"text\" , keep='first')\n",
    "    \n",
    "    return df\n",
    "\n",
    "#function for remove pattern in the input text\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for word in r:\n",
    "        input_txt = re.sub(word, \"\", input_txt)\n",
    "    return input_txt\n",
    "\n",
    "\n",
    "# Sentiment calculation based on compound score\n",
    "def get_sentiment(score):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment based on the compound score.\n",
    "    \"\"\"\n",
    "    result = 0  # Neutral by default\n",
    "    if score >= 0.05:  # Positive\n",
    "        result = 1\n",
    "    elif score <= -0.05:  # Negative\n",
    "        result = -1\n",
    "\n",
    "    #print(f\"Compound: {score}, Result: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcf2159c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (320, 6)\n",
      "Data Shape: (320, 6)\n",
      "Data Shape: (320, 6)\n"
     ]
    }
   ],
   "source": [
    "# making a dataframe with the bloomberg news\n",
    "df1 = get_tweets_from_user(\"markets\")\n",
    "print(\"Data Shape: {}\".format(df1.shape))\n",
    "df1.columns = df1.columns.str.replace('text', 'tweet')\n",
    "bloomberg = df1['tweet']\n",
    "df1\n",
    "\n",
    "# making a dataframe with the wall street journal news\n",
    "df2 = get_tweets_from_user(\"wsj\")\n",
    "print(\"Data Shape: {}\".format(df2.shape))\n",
    "df2.columns = df2.columns.str.replace('text', 'tweet')\n",
    "wall_street = df2['tweet']\n",
    "df2\n",
    "\n",
    "# making a dataframe with the yahoo finance news\n",
    "df3 = get_tweets_from_user(\"yfinanceplus\")\n",
    "print(\"Data Shape: {}\".format(df3.shape))\n",
    "df3.columns = df3.columns.str.replace('text', 'tweet')\n",
    "yahoo_finance = df3['tweet']\n",
    "df3\n",
    "\n",
    "#Concat all the tweets from the news accounts\n",
    "a = {'Bloomberg':bloomberg.values, 'Wall Street':wall_street.values, 'Yahoo Finance':yahoo_finance}\n",
    "all_tweet = pd.DataFrame.from_dict(a, orient='index')\n",
    "all_tweet = all_tweet.transpose()\n",
    "df = all_tweet\n",
    "df[\"tweet\"] = df[\"Bloomberg\"].astype(str) + df[\"Wall Street\"].astype(str) + df[\"Yahoo Finance\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63492706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove twitter users\n",
    "df['clean_tweet'] = np.vectorize(remove_pattern)(df['tweet'], \"@[\\w]*\")\n",
    "\n",
    "#remove special characters, numbers and punctuations\n",
    "df['clean_tweet'] = df['clean_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "#remove short words\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: \" \".join([w for w in x.split() if len(w)>3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29c6887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = df['clean_tweet'].apply(lambda x: x.split())\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda sentence: [stemmer.stem(word) for word in sentence])\n",
    "#combine words into single sentence\n",
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = \" \".join(tokenized_tweet[i])\n",
    "    \n",
    "df['clean_tweet'] = tokenized_tweet\n",
    "df = df.drop(['tweet'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09b2ebcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_compound</th>\n",
       "      <th>tweet_pos</th>\n",
       "      <th>tweet_neu</th>\n",
       "      <th>tweet_neg</th>\n",
       "      <th>tweet_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.112492</td>\n",
       "      <td>0.082306</td>\n",
       "      <td>0.855747</td>\n",
       "      <td>0.061950</td>\n",
       "      <td>0.181250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474812</td>\n",
       "      <td>0.063248</td>\n",
       "      <td>0.079979</td>\n",
       "      <td>0.059639</td>\n",
       "      <td>0.929299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.936000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.273200</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.800750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.140550</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.128250</td>\n",
       "      <td>0.916000</td>\n",
       "      <td>0.099250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_compound   tweet_pos   tweet_neu   tweet_neg  tweet_sent\n",
       "count      320.000000  320.000000  320.000000  320.000000  320.000000\n",
       "mean         0.112492    0.082306    0.855747    0.061950    0.181250\n",
       "std          0.474812    0.063248    0.079979    0.059639    0.929299\n",
       "min         -0.936000    0.000000    0.629000    0.000000   -1.000000\n",
       "25%         -0.273200    0.044000    0.800750    0.000000   -1.000000\n",
       "50%          0.140550    0.072000    0.861000    0.051000    1.000000\n",
       "75%          0.526700    0.128250    0.916000    0.099250    1.000000\n",
       "max          0.898000    0.287000    1.000000    0.294000    1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment scores dictionaries\n",
    "tweet_sent = {\n",
    "    \"tweet_compound\": [],\n",
    "    \"tweet_pos\": [],\n",
    "    \"tweet_neu\": [],\n",
    "    \"tweet_neg\": [],\n",
    "    \"tweet_sent\": [],\n",
    "}\n",
    "\n",
    "# Get sentiment for the text and the title\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        # Sentiment scoring with VADER\n",
    "        tweet_sentiment = analyzer.polarity_scores(row[\"clean_tweet\"])\n",
    "        tweet_sent[\"tweet_compound\"].append(tweet_sentiment[\"compound\"])\n",
    "        tweet_sent[\"tweet_pos\"].append(tweet_sentiment[\"pos\"])\n",
    "        tweet_sent[\"tweet_neu\"].append(tweet_sentiment[\"neu\"])\n",
    "        tweet_sent[\"tweet_neg\"].append(tweet_sentiment[\"neg\"])\n",
    "        tweet_sent[\"tweet_sent\"].append(get_sentiment(tweet_sentiment[\"compound\"]))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Attaching sentiment columns to the News DataFrame\n",
    "tweet_sentiment_df = pd.DataFrame(tweet_sent)\n",
    "\n",
    "# Describe dataframe\n",
    "tweet_sentiment_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4540f96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (317, 6)\n",
      "Data Shape: (34, 6)\n",
      "Data Shape: (320, 6)\n"
     ]
    }
   ],
   "source": [
    "# making a dataframe with the bloomberg news\n",
    "df4 = get_tweets_from_user(\"CMTAssociation\")\n",
    "print(\"Data Shape: {}\".format(df4.shape))\n",
    "df4.columns = df4.columns.str.replace('text', 'tweet')\n",
    "CMTAssociation = df4['tweet']\n",
    "df4\n",
    "\n",
    "# making a dataframe with the wall street journal news\n",
    "df5 = get_tweets_from_user(\"ParetsJc\")\n",
    "print(\"Data Shape: {}\".format(df5.shape))\n",
    "df5.columns = df5.columns.str.replace('text', 'tweet')\n",
    "ParetsJc = df5['tweet']\n",
    "df5\n",
    "\n",
    "# making a dataframe with the wall street journal news\n",
    "df6 = get_tweets_from_user(\"allstarcharts\")\n",
    "print(\"Data Shape: {}\".format(df6.shape))\n",
    "df6.columns = df6.columns.str.replace('text', 'tweet')\n",
    "allstarcharts = df6['tweet']\n",
    "df6\n",
    "\n",
    "#Concat all the tweets from the news accounts\n",
    "a = {'CMT Association':CMTAssociation.values, 'RSI Wizard':ParetsJc.values, 'J.C. Parets':allstarcharts.values}\n",
    "all_people_tweet = pd.DataFrame.from_dict(a, orient='index')\n",
    "all_people_tweet = all_people_tweet.transpose()\n",
    "new_df = all_people_tweet\n",
    "\n",
    "#combine all tweets per news in one column\n",
    "new_df[\"tweet\"] = new_df[\"CMT Association\"].astype(str) + new_df[\"RSI Wizard\"].astype(str) + new_df[\"J.C. Parets\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb8a2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove twitter users\n",
    "new_df['clean_tweet'] = np.vectorize(remove_pattern)(new_df['tweet'], \"@[\\w]*\")\n",
    "\n",
    "#remove special characters, numbers and punctuations\n",
    "new_df['clean_tweet'] = new_df['clean_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "#remove short words\n",
    "new_df['clean_tweet'] = new_df['clean_tweet'].apply(lambda x: \" \".join([w for w in x.split() if len(w)>3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "951b0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = new_df['clean_tweet'].apply(lambda x: x.split())\n",
    "tokenized = tokenized.apply(lambda sentence: [stemmer.stem(word) for word in sentence])\n",
    "\n",
    "#combine words into single sentence\n",
    "for i in range(len(tokenized)):\n",
    "    tokenized[i] = \" \".join(tokenized[i])\n",
    "\n",
    "new_df['clean_tweet'] = tokenized\n",
    "new_df = new_df.drop(['tweet'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "835422e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_compound2</th>\n",
       "      <th>tweet_pos2</th>\n",
       "      <th>tweet_neu2</th>\n",
       "      <th>tweet_neg2</th>\n",
       "      <th>tweet_sent2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.222898</td>\n",
       "      <td>0.124269</td>\n",
       "      <td>0.832334</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.393750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.391021</td>\n",
       "      <td>0.127048</td>\n",
       "      <td>0.138622</td>\n",
       "      <td>0.079622</td>\n",
       "      <td>0.747802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.765000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.743500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.273200</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.971700</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_compound2  tweet_pos2  tweet_neu2  tweet_neg2  tweet_sent2\n",
       "count       320.000000  320.000000  320.000000  320.000000   320.000000\n",
       "mean          0.222898    0.124269    0.832334    0.043400     0.393750\n",
       "std           0.391021    0.127048    0.138622    0.079622     0.747802\n",
       "min          -0.765000    0.000000    0.455000    0.000000    -1.000000\n",
       "25%           0.000000    0.000000    0.743500    0.000000     0.000000\n",
       "50%           0.273200    0.110500    0.843000    0.000000     1.000000\n",
       "75%           0.526700    0.205000    1.000000    0.081250     1.000000\n",
       "max           0.971700    0.545000    1.000000    0.459000     1.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment scores dictionaries\n",
    "tweet_sent2 = {\n",
    "    \"tweet_compound2\": [],\n",
    "    \"tweet_pos2\": [],\n",
    "    \"tweet_neu2\": [],\n",
    "    \"tweet_neg2\": [],\n",
    "    \"tweet_sent2\": [],\n",
    "}\n",
    "\n",
    "# Get sentiment for the text and the title\n",
    "for index, row in new_df.iterrows():\n",
    "    try:\n",
    "        # Sentiment scoring with VADER\n",
    "        tweet_sentiment2 = analyzer.polarity_scores(row[\"clean_tweet\"])\n",
    "        tweet_sent2[\"tweet_compound2\"].append(tweet_sentiment2[\"compound\"])\n",
    "        tweet_sent2[\"tweet_pos2\"].append(tweet_sentiment2[\"pos\"])\n",
    "        tweet_sent2[\"tweet_neu2\"].append(tweet_sentiment2[\"neu\"])\n",
    "        tweet_sent2[\"tweet_neg2\"].append(tweet_sentiment2[\"neg\"])\n",
    "        tweet_sent2[\"tweet_sent2\"].append(get_sentiment(tweet_sentiment2[\"compound\"]))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Attaching sentiment columns to the News DataFrame\n",
    "tweet_sentiment_df2 = pd.DataFrame(tweet_sent2)\n",
    "\n",
    "# Describe dataframe\n",
    "tweet_sentiment_df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb32acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
